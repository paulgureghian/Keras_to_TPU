{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_on_TPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulgureghian/Keras_to_TPU/blob/master/Keras_on_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "koXmX8ppd9uB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Created by Paul A. Gureghian in April 2019.**\n"
      ]
    },
    {
      "metadata": {
        "id": "7XEZ62qzePlz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **This scientific notebook contains Python code on how to train an LSTM Model using Keras and Google CoLaboratory with TPUs to exponentially reduce training time compared to a GPU on a local machine.**"
      ]
    },
    {
      "metadata": {
        "id": "3DP7pRY3fBGY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **An overview of the workflow.**\n",
        "\n",
        "* Build a Keras model for training in functional API with static input batch_size.\n",
        "* Convert Keras model to TPU model.\n",
        "* Train the TPU model with static batch_size * 8 and save the weights to file.\n",
        "* Build a Keras model for inference with the same structure but variable batch input size.\n",
        "* Load the model weights.\n",
        "* Predict with the inferencing model."
      ]
    },
    {
      "metadata": {
        "id": "msQpuZ3gf7h6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Import packages\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.layers import Input, LSTM, Bidirectional, Dense, Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20e_UeM7g8pk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0b3307a-a17e-4775-92c3-a67b0d596990"
      },
      "cell_type": "code",
      "source": [
        "### Define some training parameters, and download the dataset\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 10000\n",
        "# Cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 500\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print('IMDB Downloaded')\n",
        "\n",
        "# Reverse sequences\n",
        "x_train = [x[::-1] for x in x_train]\n",
        "x_test = [x[::-1] for x in x_test]\n",
        "\n",
        "# Pad sequences\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMDB Downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bUTTnjUPga5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define 'make_model' function\n",
        "\n",
        "def make_model(batch_size=None):\n",
        "    source = Input(shape=(maxlen,), batch_size=batch_size,\n",
        "                   dtype=tf.int32, name='Input')\n",
        "    embedding = Embedding(input_dim=max_features,\n",
        "                          output_dim=128, name='Embedding')(source)\n",
        "    lstm = LSTM(32, name='LSTM')(embedding)\n",
        "    predicted_var = Dense(1, activation='sigmoid', name='Output')(lstm)\n",
        "    model = tf.keras.Model(inputs=[source], outputs=[predicted_var])\n",
        "    model.compile(\n",
        "        optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UXTPv9TJiwLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "26b99860-fc95-4d6e-d0aa-47af103c0cf2"
      },
      "cell_type": "code",
      "source": [
        "### Print Keras model summary\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "training_model = make_model(batch_size = 128)\n",
        "training_model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (128, 500)                0         \n",
            "_________________________________________________________________\n",
            "Embedding (Embedding)        (128, 500, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "LSTM (LSTM)                  (128, 32)                 20608     \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (128, 1)                  33        \n",
            "=================================================================\n",
            "Total params: 1,300,641\n",
            "Trainable params: 1,300,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LIHpGxsRljK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Convert Keras model to TPU model.**"
      ]
    },
    {
      "metadata": {
        "id": "AH_WBl9hluuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b2e13ee7-b83b-4dcd-90b7-c548c16d54b6"
      },
      "cell_type": "code",
      "source": [
        "### Use a builtin TensorFlow function to convert Keras to TPU\n",
        "\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    training_model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.116.189.10:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 10432534271108538128)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17569796570915582283)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4595398824277185729)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5257321798323247484)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1773730139355646359)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9959772193105499582)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13854017446956188841)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 4719566969970533284)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13692108894644102729)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5054852965843331405)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 14038038451405527834)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nb6bILWkpLS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0bd9bba9-9bed-46bc-d01c-8a729b117d85"
      },
      "cell_type": "code",
      "source": [
        "### Print TPU model summary\n",
        "\n",
        "tpu_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (128, 500)                0         \n",
            "_________________________________________________________________\n",
            "Embedding (Embedding)        (128, 500, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "LSTM (LSTM)                  (128, 32)                 20608     \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (128, 1)                  33        \n",
            "=================================================================\n",
            "Total params: 1,300,641\n",
            "Trainable params: 1,300,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nr9OnCh-qj_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        },
        "outputId": "bf189b48-f433-479c-82da-fd683beb435a"
      },
      "cell_type": "code",
      "source": [
        "### Train the TPU model\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = tpu_model.fit(x_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=128 * 8,\n",
        "                    validation_split=0.2)\n",
        "tpu_model.save_weights('./tpu_model.h5', overwrite=True)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(128, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 3.7073402404785156 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "23552/25000 [===========================>..] - ETA: 0s - loss: 0.6931 - acc: 0.5028INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(53,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(53, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(53, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.479305267333984 secs\n",
            "24576/25000 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.5029INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(128, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(128, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 5.582892894744873 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(113,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(113, 500), dtype=tf.int32, name='Input_10'), TensorSpec(shape=(113, 1), dtype=tf.float32, name='Output_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for Input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 7.007689952850342 secs\n",
            "25000/25000 [==============================] - 39s 2ms/sample - loss: 0.6931 - acc: 0.5032 - val_loss: 0.6931 - val_acc: 0.5062\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 3s 114us/sample - loss: 0.6931 - acc: 0.5046 - val_loss: 0.6932 - val_acc: 0.4952\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 3s 114us/sample - loss: 0.6931 - acc: 0.5044 - val_loss: 0.6930 - val_acc: 0.5044\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 3s 112us/sample - loss: 0.6930 - acc: 0.5102 - val_loss: 0.6945 - val_acc: 0.4938\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 3s 112us/sample - loss: 0.6920 - acc: 0.5204 - val_loss: 0.6892 - val_acc: 0.5452\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 3s 110us/sample - loss: 0.6894 - acc: 0.5628 - val_loss: 0.6803 - val_acc: 0.5358\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 3s 110us/sample - loss: 0.6742 - acc: 0.6170 - val_loss: 0.5984 - val_acc: 0.6904\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 3s 112us/sample - loss: 0.6580 - acc: 0.6189 - val_loss: 0.9150 - val_acc: 0.5018\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 3s 110us/sample - loss: 0.5981 - acc: 0.6954 - val_loss: 0.4866 - val_acc: 0.7930\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 3s 110us/sample - loss: 0.4983 - acc: 0.7712 - val_loss: 0.5425 - val_acc: 0.7172\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 3s 112us/sample - loss: 0.3802 - acc: 0.8396 - val_loss: 0.3161 - val_acc: 0.8724\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 3s 113us/sample - loss: 0.2704 - acc: 0.8936 - val_loss: 0.3056 - val_acc: 0.8642\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 3s 111us/sample - loss: 0.2181 - acc: 0.9166 - val_loss: 0.1400 - val_acc: 0.9546\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 3s 111us/sample - loss: 0.1714 - acc: 0.9383 - val_loss: 0.1178 - val_acc: 0.9640\n",
            "Epoch 15/20\n",
            "25000/25000 [==============================] - 3s 112us/sample - loss: 0.1272 - acc: 0.9551 - val_loss: 0.0829 - val_acc: 0.9774\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 3s 114us/sample - loss: 0.0911 - acc: 0.9681 - val_loss: 0.0677 - val_acc: 0.9778\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 3s 113us/sample - loss: 0.0685 - acc: 0.9771 - val_loss: 0.0368 - val_acc: 0.9898\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 3s 111us/sample - loss: 0.0477 - acc: 0.9842 - val_loss: 0.0307 - val_acc: 0.9918\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 3s 111us/sample - loss: 0.0488 - acc: 0.9840 - val_loss: 0.0150 - val_acc: 0.9956\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 3s 110us/sample - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0331 - val_acc: 0.9932\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "--- 98.36971139907837 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3trIn_IHr7Tx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "e2bf03e7-d730-4465-af6e-998c804c4b6c"
      },
      "cell_type": "code",
      "source": [
        "### Evaluluate the model\n",
        "\n",
        "tpu_model.evaluate(x_test, y_test, batch_size=128 * 8)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-eded192c0e06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtpu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1579\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         return super(KerasTPUModel, self).evaluate(x, y, batch_size, verbose,\n\u001b[0;32m-> 1581\u001b[0;31m                                                    sample_weight, steps)\n\u001b[0m\u001b[1;32m   1582\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         self._numpy_to_infeed_manager_list = (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    978\u001b[0m             self._distribution_strategy, first_x_value, steps, batch_size)\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_validate_or_infer_batch_size\u001b[0;34m(self, batch_size, steps, x)\u001b[0m\n\u001b[1;32m   1587\u001b[0m           raise ValueError('The `batch_size` argument value {} is incompatible '\n\u001b[1;32m   1588\u001b[0m                            \u001b[0;34m'with the specified batch size of your Input Layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m                            '{}'.format(batch_size, static_batch_size))\n\u001b[0m\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m         \u001b[0;31m# Check Dataset/Iterator batch size is consistent with InputLayer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `batch_size` argument value 1024 is incompatible with the specified batch size of your Input Layer: 128"
          ]
        }
      ]
    }
  ]
}